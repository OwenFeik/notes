\documentclass[12pt]{report}

\usepackage{import}
\import{../}{preamble.tex}

\begin{document}
\begin{flushleft}

\section*{Electromagnetism}

When dealing with electrostatics, very small units are often required.
It therefore bears revising some of the smaller SI prefixes.
\begin{itemize}
    \item \(\mu = 10^{-6}\) (micro)
    \item \(n = 10^{-9}\) (nano)
    \item \(p = 10^{-12}\) (pico)
\end{itemize}

\subsection*{History}
Electricity was first observed in ancient Greece, where static electricity was
observed in amber. The name for electricity comes from the Greek word for 
amber, ``elektron''. Magnetism was discovered around the same time, but it took
many years for a connection between the two to be established. Only in 1820 did
H.C. Oersted identify the connection. In the late 19th century, Maxwell's 
equations quantified links between electricity and magnetism, and finally the
two were unified by Einstein in 1905, through the theory of special relativity.
This course only teaches up to slightly before 1905.

\subsection*{Charge}
Electromagnetism is one of the four fundamental forces of nature.
\begin{itemize}
    \item Gravitational force
    \item Electromagnetism
    \item Strong force
    \item Weak force
\end{itemize}
The gravitational force is often modelled through Newton's law.
\[F = \frac{Gm_1m_2}{r^2}\hat{r}\]
Electromagnetism mirrors this with Coulomb's Law, dating to 1798.
\[F = \frac{kq_1q_2}{r^2}\hat{r}\]
Where \(k\) is Coulomb's constant and \(q_1\) and \(q_2\) are the two charged
particles interacting. Here, \(\hat{r}\) is the vectore direction defined by
the two charges. \par
While gravity is only positive, electric charge comes in both positive and
negative forms. This charge is measured in Coulombs.
\[1C = 1A \times 1s\]
A Coulomb is a large quantity of charge. Charge is often denoted with \(q\).
As an example, the charge of an electron is
\[1.6 \times 10^{-19}C\]
Charge is often generated by scraping electrons from surfaces, or by touching
conductive surfaces together. 
Charge is quantised; it comes in integer quantities. It can be transferred, but
it cannot be created or destroyed.

\subsubsection*{Conductors}
A conductor contains electrons no strongly bound to any particular nucleus 
within the conductor. These \textit{free electrons} can move when under the
influence of an electric field, creating an electric current. There are huge
quantities of these free electrons available in an ordinary conductor. For
example, copper contains around \(10^{22}\) free electrons per cubic 
centimetre. These are initially held by attractive forces with the nuclei, but
can be moved along by external forces.

\bigskip
The counterpart to a conductor is an insulator, which have very few free 
electrons.

\bigskip
A process of charging by induction entails placing a charged body near to a
neutral body. This will attract the opposite charges of the neutral body to one
side. If the neutral body is then grounded, it will now be charged.

\subsubsection*{Electric Force}
Electric force is calculated, as touched on above, through Coulomb's law.
\[F = \frac{kq_1q_2}{r^2}\hat{r}\]
Here, \(F\) is the electric force in Newtons between the two charged bodies,
\(q_1\) and \(q_2\) are the charges of the two bodies involved, \(r\) is the
distance between the two, \(\hat{r}\) is a unit vector in the direction
between \(q_1\) and \(q_2\) and 
\(k = 8.988\times10^9\mathrm{Nm}^2\mathrm{C}^{-2}\). If this value \(F\) is
negative, the two are attracting each other, otherwise they are repelling each
other.

\bigskip
\(k\) is defined in terms of the \textit{permittivity of free space}, 
\(\epsilon_0\) according to
\[k = \frac{1}{4\pi\epsilon_0}\]
Here, \(\epsilon_0 = 8.85\times10^{-12}\mathrm{C^2N^{-1}m^{-2}}\). This value
is for the permittivity of free space, i.e. vacuum, and a different value is
required to accurately model force between charges with material lying between
them, known as the permittivity for that material. With this value, the 
behaviour of electric force for any material can be clearly defined.

\bigskip
The \textit{superposition principle} allows us to add electric forces (or any
forces) on a particle to determine the resultant force on that particle. This
can be done in either a single direction or using vector addition in multiple
directions. If two identical particles interact from opposite sides with a
particle, their effects will cancel.

\subsubsection*{Electric Fields}
An application of superposition comes in electric fields, where we can use
integration to apply the concept of superposition across a continuous field.
For a linear charge distribution, along a single straight line in the \(x\) 
direction, this integral looks like  
\[F_{q_0} = \int_{x_i}^{x_f} \frac{kq_0}{r_{0x}^2}\hat{r}_{0x}\lambda(x)\dx\]
Here, \(x_i\) through \(x_f\) is the range of charges along the line, \(k\) is
Coulomb's constant, \(q_0\) is the charge of the particle being considered, 
\(r_{0x}\) is the distance to the particle from each point \(x\), 
\(\vec{r}_{0x}\) is the vector between the particle and the point and
\(\lambda(x)\) is the \textit{linear charge density}, a function defining the
charge of the line at any point \(x\), measured in \(\mathrm{Cm}^{-1}\). \par
For a surface charge distribution, for example of a sphere, the integral
looks like
\[F_{q_0} = \int_{S} \frac{kq_0}{r_{0\mathrm{d}A}^2}\hat{r}_{0\mathrm{d}A}
\sigma(\mathrm{d}A)\:\mathrm{d}A\]
Here, we exchange linear position \(x\) for rate of change of area 
\(\mathrm{d}A\). We also exchange \(\lambda\) for \(\sigma\), the surface
charge density function for the body. \par
Finally, we can consider charge distribution throughout a volume
\[F_{q_0} = \int_{V} \frac{kq_0}{r_{0\mathrm{d}V}^2}\hat{r}_{0\mathrm{d}V}
\rho(\mathrm{d}V)\:\mathrm{d}V\]
In this case, integration across area becomes integration across volume, and
we exchange rate of change of area for rate of change of volume. \(\sigma\)
becomes \(\rho\), the volume charge density function.

\bigskip
We consider electric field lines through the construct of electric field lines.
These are imaginary lines flowing away from positive charges toward negative
charges, terminating at infinity or negative charges. The density of these 
lines is greatest around charges, which is where the electric field is 
strongest. Field lines are always perpendicular to the surface of a conductor.
Using this concept, we can define the electric field \(\vec{E}\) for a point
charge as
\[\vec{E} = \frac{\vec{F}}{q}\]
If we use \(\vec{F} = \frac{kq_1q_2}{r^2}\hat{r}\), we can find the value for
the electric field strength at a distance \(r\) to be
\[\vec{E} = \frac{kq}{r^2}\hat{r}\]
This yields a value in units of \(\mathrm{NC}^{-1}\) or equivalently 
\(\mathrm{Vm}^{-1}\). Here \(q\) is the charge of the particle creating the 
field. For a system of charges, we can sum across the effects of individual
charges on a charge in the resultant field.

\bigskip
For a dipole system, with a positive and negative charge seperated by a 
distance \(s\), as shown below, a special equation can be used to calculate
the field strength at a distance \(r\).
\begin{plot}[
    xmin = -1,
    xmax = 4,
    ymin = -3,
    ymax = 3,
    xticklabels = none,
    yticklabels = none,
]
    \addplot[black, dashed] coordinates {(0, 1)(2, 0)};
    \addplot[black, dashed] coordinates {(0, -1)(2, 0)};
    \addplot[black, dashed] coordinates {(-0.15, 1)(-0.15, -1)}
    node[left, pos = 0.4] {\(s\)};
    \addplot[black, dashed] coordinates {(0.1, 1.15)(2, 1.15)}
    node[above, pos = 0.5] {\(r\)};
    \addplot[ultra thick, black, ->] coordinates {(2, 0)(2.5, -0.25)}
    node[below right] {\(\vec{E}_+\)};
    \addplot[ultra thick, black, ->] coordinates {(2, 0)(1.5, -0.25)}
    node[below left, pos = 0.6, yshift = -0.1cm] {\(\vec{E}_-\)};
    \addplot[ultra thick, black, ->] coordinates {(2, 0)(2, -0.5)}
    node[below] {\(\vec{E}_\mathrm{dipole}\)};

    \fill[blue] (axis cs: 0, -1) circle[radius = 5pt];
    \fill[red] (axis cs: 0, 1) circle[radius = 5pt]
    node[below right, black] {\(\theta\)};
    \fill[red] (axis cs: 2, 0) circle[radius = 5pt];
\end{plot}
Here, \(\vec{E}_\mathrm{dipole}\) can be calculated through
\[\frac{kqs}{r^3}\]

\bigskip
Returning again too a linear line of charge, we can consider a case where
\(\lambda\) is a constant function; that is the charge per unit length of the
body is constant throughout. In this case, for a point \(p\) at some distance
\(r\) from the line, the force from two points an equal distance perpendicular
to \(r\) will cancel in the perpendicular direction, leaving only the force
in the direction of the radius. The resultant force vector on \(p\) will 
therefore be directly away from the linear charge line. The magnitude of this
field can be calculated through
\[\vec{E} = \frac{2k\lambda}{r}\hat{r}\]

\subsubsection*{Gauss' Law}
Coulomb's law works best for point charges, and can be generalised through
integration to a broader range of charges. Gauss' law is another law for force
due to electric charge, and can be applied to all charge distributions. Gauss'
law is one of Maxwell's equations; in a way it is a fundamental law of nature.
\par
Gauss' law requires the relevant problem to have symmetry, perhaps cartesian or
cylindrical. The symmetry may be translational, rotational or reflective. For a
point charge, Gauss' law is the same as Coulomb's law:
\[\vec{E} = \frac{kQ}{r^2}\hat{r} =\frac{1}{4\pi\epsilon}\frac{Q}{r^2}\hat{r}\]
This can be equivalently expressed as
\[\vec{E}4\pi r^2 = \frac{Q}{\epsilon}\]
Which can be intuitively understood as the surface area of a sphere multiplied
by the field strength at any point on the surface of the sphere being equal to
the charge of the particle divided by the permittivity of the material.

\bigskip
Flux is an important concept in electric fields. In fluid mechanics, flux 
describes the volume per unit time flowing through an area. If the area 
described is perpendicular to the flow, flux through it is at maximum. If 
perpendicular, the flux is \(0\).  If we define the angle of the area to the
perpendicular direction as \(\theta\), then we can define flux through that 
area in an electric field as
\[\Phi = EA\cos(\theta)\]
Where \(E\) is the field strength. This can be equivalently expressed if we
define a vector \(\vec{A}\) to be the direction of the area and \(\vec{v}\) to
be the flow of material as
\[\Phi = \vec{v} \cdot \vec{A}\]
With electric field as the flow of material this becomes \(E \cdot \vec{A}\).
Using Gauss' law, this generalises from simple planar areas to more complex
\textit{Guassian surfaces}, which are simply surfaces of any three dimensional 
body. The electric field through these surfaces can then be calculated by 
integration across the surface, considering the electric field at each 
infinetismal point by taking the dot product of the surface vector at that
point and the electric field at that point, yielding
\[\Phi = \int\vec{E}\cdot\mathrm{d}\vec{A}\]
The units of electric flux are \(\mathrm{Nm}^2\mathrm{C}^{-1}\). 
\(\mathrm{d}\vec{A}\) is a vector with direction given by the surface normal 
and magnitude of the area of the surface. In the case of a closed surface 
another simplification applies
\[\Phi = \oint_\mathrm{surface}\vec{E}\cdot\mathrm{d}\vec{A} = 
\frac{q_\mathrm{enclosed}}{\epsilon_0}\]
This states that the electric flux through a closed surface is equal to the
enclosed charge divided by \(\epsilon_0\). Thus we can simply sum the internal
charges to find the charge through the surface.

\bigskip
For an infinite line of charge, with charge density \(\lambda\), the electric
field at a distance \(r\) from the line is given by
\[\vec{E} = \frac{\lambda}{2\pi\epsilon_0}\hat{r}\]
For an insulating sheet of charge, with charge density \(\sigma\), the electric
field strength at a distance \(r\) from the sheet has direction normal to the 
sheet and magnitude given by
\[E = \frac{\sigma}{2\epsilon_0}\]

\bigskip
For a charged conductor, the electric field projected will always be normal to
the surface, and will always be zero internally. This is because the conductor
will inherently balance internal forces until \(0\) net field exists. Near to
the surface of such a conductor, the electric field, normal to the surface as
stated, will have field strength given by
\[E = \frac{\sigma}{\epsilon_0}\]
This is applicable on in areas where the conductor is sheet-like; either on a 
flat area or on a small enough section of a curve to make the curve irrelevant.
The reason for the behaviour of the conductor in this way is that the like 
charges repel each other, forcing an even distribution across the outer surface
of the conductor. \par
This applies equally to a hollow conductor. For a torus shaped conductor, the
inner radius will have no charges upon it. For this reason, lightning poses 
minimal risk to a person inside a conducting vehicle like a car. Here the car
acts as a \textit{Faraday cage}.

\subsubsection*{Electric Potential Energy}
It becomes quite complex to accurately describe the electric field at a 
specific point in space. It can therefore be useful to uniquely define a 
potential energy for a point in space; an analogue to the gravitational 
potential energy at a given height. \par
For example, if a positive charge is placed near another positively charged
object, the charge now has potential to move away from the object. Work will be
required to move it closer, and it will gain kinetic energy as it is repelled.
Electrice force is \textit{conservative}, just as gravity is. It is this 
property that allows potential to be uniquely defined with respect to space.

\bigskip
Work in an electric field is described just as mechanical work is, as force
times distance, though in this case our force is electrical force, \(qE\).
\[W = q\vec{E}\cdot\vec{d}\]
\[W = qEd\]
Work done against the field is negative. When work is done against the field,
the electric potential \(U\) increases, i.e. \(\Delta U > 0\). When potential
energy is lost, kinetic energy is gain, work done is positive. The dot product
in the above equation tells us that force at right angles to the field does
not entail a loss in potential energy, and also allows us to use the equation
in the general case through the use of vector arguments.

\subsubsection*{Electric Potential}

Electric potential energy, \(U\) differs from electric potential \(V\).
\begin{itemize}
    \item While \(U\) is a property of a system of charges and interacting 
        electric fields, \(V\) is independent of interacting charges.
    \item \(U\) at a point is not a property of in space, nor is the
        difference in potential between two points. \(V\) is a property of
        two points in space and the difference in potential between them.
    \item \(U\) is dependent on the charge, \(q\), which \(V\) is made 
        independent by dividing through \(U\) by \(q\).
\end{itemize}
\[V(P) = \frac{U(P)}{q}\]
Whenever a charge moves in a field, the change in \(U\) is proportional to
the charge, while the change in potential per unit charge is independent.
\[\Delta V = V_f - V_i = \frac{\Delta U}{q}\]
i.e. the change in electric potential is equal to initial potential minus final
potential is equal to change in electric potential energy divided by charge. 
The unit of electric potential is the Volt \(\mathrm{V}\), \(1\mathrm{V} = 
1 \mathrm{JC}^{-1}\). Electric fields can also be equivalently measured in 
\(\mathrm{Vm}^{-1}\) rather than \(\mathrm{NC}^{-1}\). \par
Potential itself has no meaning; only differences in potential have meaning.
Therefore, we can define zero according to convenience. Usually this is done
as either a charge at infinite distance or the charge of the earth. \par
In general \(E\) points towards regions of low \(V\) and away from high \(V\).
If one moves perpendicular to a field line through an electric field, one is
traversing an equipotential line, moving about without changing potential. For
a point charge, the electric potential at a distance \(r\) is given by
\[\frac{1}{4\pi\epsilon_0}\frac{Q}{r} = \frac{kQ}{r}\]
It is directly proportional to distance. For an infinite line of charge, the
change in potential when moving from position \(r_1\) to position \(r_2\) is
given by
\[V_2 - V_1 = \Delta V = -\frac{\lambda}{2\pi\epsilon_0}
\log\left(\frac{r_2}{r_2}\right)\]
For a hollow conductor, such as a hollow sphere, the potential inside the 
conductor must be the same as the potential at the surface. \par
To find the electric potential at a point \(P\) affected by multiple charges,
one can simply sum the potential of the individual charges to find the 
resultant potential at \(P\).
\[V(P) = V_1(P) + V_2(P) + \ldots + V_n(P) = \frac{U}{q}\]
This is equivalent to the potential divided by the charge.

\subsubsection*{Pointy Conductors}

Consider a conductor which at one end comes to a point. This can be 
approximated by considering a large sphere in proximity to a smaller sphere,
connected by an conductor between the two. In this case, the potential of the
system must be uniform, and therefore a greater proportion of the system's 
charge must be distributed around the radius of the larger sphere. In fact,
the ratio of charges is equivalent to the ratio of the radii, i.e.
\[\frac{q_1}{q_2} = \frac{r_1}{r_2}\]
If we then consider the electric field around each sphere, we find that for
a larger sphere \(1\) and a smaller sphere \(2\)
\[\frac{E_1}{E_2} = \frac{q_2}{q_2}\frac{r_2^2}{r_1^2} = \frac{r_2}{r_1}\]
\[\therefore r_2 < r_1 \Rightarrow E_2 > E_1\]
To summarise, a smaller radius implies a larger electric field. It is for this
reason that lightning tends to strike sharp points, such as the Eiffel Tower.
For the same reason it is dangerous to be atop a mountain during a 
thunderstorm.

\subsubsection*{Electric Dipoles}

Due to the strength of the electric force, it is rare to encounter free charges
in nature. More common are dipoles, conductors with a positive and negative 
pole. \par
A dipole with two charges of equal magnitude in a uniform electric field will
experience equal force to each pole. If the dipole is not parallel to the
direction of the field, it will experience a torque. The magnitude of this
torque will be
\[\tau = Fd\sin(\theta) = qdE\sin(\theta)\]
Where \(d\) is the distance between the two poles of the dipole, each of which
have charge magnitude \(q\). A dipole is often defined as a vector \(p\) where
\[p = qd\]
and \(p\) points from the negative to positive terminal of the dipole. Using
this vector representation, we find that the torque is given by
\[\vec{\tau} = \vec{p} \times \vec{E}\]
To rotate against this field, work must be done on the dipole. When the dipole
is parallel with the field, \(\theta = 0 \Rightarrow \tau = 0\). For the dipole
to rotate to some other angle, work must be done, and the magnitude of this 
work is given by
\[W = \tau\theta\]
The potential energy of the system at any angle is given by the dot product
\[U = -\vec{p} \cdot \vec{E}\]

\subsection*{Capacitors}

A capacitor stores the energy of an electric field. It does this by separating
positive and negative electric charges within itself. Generally, capacitors use
two sheets of electric foil, often coiled into a cylinder. The total charge 
within the capacitor is also zero, though often with a large positive and a 
large negative charge. Between these two plates, a potential difference given
by
\[V = \frac{qd}{A\epsilon_0}\]
Where \(A\) is the area of the two plates and \(d\) is the distance between 
them. In the case that there is air or another material rather than vacuum 
between the two plates, a different \(\epsilon\) must of course be used. This
expression for the potential difference within the capacitor leads to a 
definition of the \textit{capacitance} of the capacitor.
\[C = \frac{\epsilon_0A}{d}\]
\[\Rightarrow q = CV\]
Here \(C\) is measured in units of \(\mathrm{CV}^{-1}\) or Farads, 
\(\mathrm{F}\). The definition above is for a parallel plate capacitor; other
shapes may have subtly different expressions. To create capacitors with high
capacitance, it is common to use a material with a different \(\epsilon\) 
rather than change the seperation or area. \(d\) can be extremely small; in 
applications like DRAM it is often as little as \(50\mathrm{nm}\).

\subsubsection{Energy Storage in Capacitors}

Charging a capacitor requries energy, as electrons are forced onto the plates.
The internal energy of a capacitor is given by
\[U = \frac{1}{2}\frac{q^2}{C} = \frac{1}{2}CV^2\]
If potential is fixed, say by a battery, the energy stored can be increased
through higher capacitance. If the charge is fixed, increasing the capacitance
decreases the potential energy. Increasing voltage is a very effective way to
increase the energy stored of a capacitor. It is useful to be able to talk 
about energy density of a capacitor, the formula for which is
\[\frac{1}{2}\epsilon_0E^2\]
Assuming a vacuum, otherwise an appropriate \(\epsilon\) must be used. 
Interestingly, this formula can be used for \textit{all} electric fields, with
units of \(\mathrm{Jm}^{-3}\). When changing capacitance by using a non-vacuum
filling material, we use the formula
\[C = \frac{\kappa\epsilon_0A}{d} = \frac{\epsilon A}{d}\]
Where \(\kappa\) is the \textit{dielectric constant}, a coefficient to 
\(\epsilon_0\) which relates the permittivity of the material to that of free 
space. This higher \(\epsilon\) allows for a significantly higher storage of
energy. However, if the field becomes too strong, the dielectric will fail.
We therefore have a concept of dielectric strength, which informs of the 
maximum field which can be created across the material without destruction. 
\par
A defibrillator is an example of a very high capacitance application, where a
material boasting a very high \(\kappa\) is utilised.

\subsubsection*{Capacitance in Circuits}

Capacitors in parallel add their capacitance. Effectively, the surface areas of
the individual capacitors add.
\[C_T = \sum_{i\rightarrow n} C_i\]
For capacitors in series, the capacitance adds similarly to resistors in 
parallel. 
\[\frac{1}{C_T} = \sum_{i\rightarrow n} \frac{1}{C_i}\]
This is because the charge between the negative terminal of one must be 
adjacent to the positive terminal of another, and the charge between the two
must be neutral.

\subsection*{Electric Current}

Around an atom, energy exists in quantised levels. Electrons exist in shells
around a nucleus, and each shell has a different binding energy. The number of
electrons that can fit within each shell is different, beginning with two and
increasing moving toward outer shells. \par
Insulators are more tightly bound than are conductors. In conductors, electrons
can move around more freely and conduct to other particles. This implies that 
there is a relatively large gap between energy bands of the particle. \par
Semiconductors have a smaller gap between bands than conductors, but larger 
than insulators. By changing their conductivity by introducing traces of
conductors or altering the temperature, one can control their conducting 
behaviour. \par
Electrons naturally move around rapidly and largely randomly, but by applying
a force to them with an electric field, this random motion can be skewed toward
one end of the circuit resulting in a flow of electricity. Electric current is
the rate of transport of charge along a conductor.
\[I = \frac{\mathrm{d}q}{\mathrm{d}t}\]
This value \(i\) can be calculated by considering the movement of individual
electrons within a conductor, according to the following formula.
\[\frac{\mathrm{d}q}{\mathrm{d}t} = enAv_d = I\]
Here, \(e\) is the charge of an electron, \(n\) is the density of electrons in
the conducting material, \(A\) is the cross sectional area of the flow
direction in in the conductor and \(v_d\) is the drift speed of an electron.
Current is measured in Amps, \(\mathrm{A}\) equal to \(\mathrm{Cs}^{-1}\).
\par
A material with a lower \(v_d\) generally has more things for a flowing 
electron to ``bump in to'', causing it to slow down, and might be said to have
a higher resistance. This resistance is defined more formally through
\[R = \frac{V}{I}\]
Generally, \(R\) is dependent on temperature, voltage and current. A 
superconductor has \(0\) resistance, implying a free flow of electrons. A
device with a linear relationship between \(I\) and \(V\) is an Ohmic resistor.
\par
Power is defined as the product of current and voltage, i.e.
\[P = VI\]
When electricity passes through a material, electrons are bumping into the 
material, releasing heat into it, causing the material to heat up and wasting
power. For a resistor with resistance \(R\omega\), the power dissipated is
\[P_\mathrm{lost} = I^2R\]
It is for this reason that power lines are run at very high voltages like 
\(500\mathrm{kV}\). Because power loss is related to the square of current,
running at a high voltage allows the same delivery of power with a much lower
power loss.

\subsection*{Circuits}

A battery in a circuit is a source of electromotive force, electric potential.
It drives current around a circuit. The electric potential in the circuit is
dissipated across the components of the circuit according to their resistances.
In the case of the resistor, the potential is converted to heat.
\[\epsilon - IR = 0\]
\[I = \frac{\epsilon}{R}\]
Here, \(\epsilon\) is electromotive, equivalent to \(V\). To understand complex
circuits, we use Kirchhoff's Rules for Circuit Analysis. These rules 
essentially dictate conservation of charge and conservation of energy within
circuits. This states that any current within a circuit must be going 
somewhere; it must traverse from one end of potential back to the same. \par
Mathematically, at any node, any combination of path, the sum of currenst must
be \(0\). This applies along a straight line; if the current all passes through
one point, the outflow equals the inflow so the sum is \(0\).
\[\sum I = 0\]
Around any loop, the following statement must be true.
\[\pm\sum\epsilon\pm\sum IR\pm\sum\frac{q}{C} = 0\]
So if we add up all of the voltage input (say batterys), voltage loss 
(say resistors) and capacitors, the sum must be \(0\), i.e. the circuit is
conservative; any gain in charge is matched by an equivalent loss. This
allows us to, for example figure out how to calculate cumulative resistors in
series as
\[R_T = \sum_{i\rightarrow n}R_i\]
It can also be used to solve for resistors in parallel, yielding the equation
\[\frac{1}{R_T} = \sum_{i\rightarrow n}\frac{1}{R_i}\]
These equations are determined by tracing the paths and considering the 
splitting of current that must occur for the circuit to obey the two 
conservations.

\subsection*{Magnetic Fields}

In electric fields, electric monopoles exert forces on each other. Magnetic
fields behave differently, as all magnetic fields are dipoles. No ``magnet
charge'' exists, instead moving charges create magnetic fields. The simplest
example of a magnet is a bar magnet. A bar magnet is a magnetic dipole, with a 
north and south pole. \par
Field lines are drawn from the north pole to the south pole, and the density of
these field lines is known as magnetic flux. This density is highest at either
of these poles. \par
The idea of all magnetic fields being dipoles can be expressed through the
previously explored idea of a closed surface integral. This is Gauss' Law of
magnetism, and is one of Maxwell's equations.
\[\oint \vec{B}\cdot\mathrm{d}\vec{A} = 0\]
This states thates that the magnetic flux through any given three dimensional
surface must be \(0\), which can be understood as the fact that any field lines
which emerge from the surface must also return through the sphere to the 
opposite pole. \par
An electric charge moving through a magnetic field will tend to move
perpendicular to that field, in an arc. This is because it has a certain force
acting on it which causes in to move in a parabola as it accelerates. The
magnitude and direction of this force is given by
\[\vec{F} = q\vec{v}\times\vec{B}\]
Where \(\vec{F}\) is the force vector on the particle with charge \(q\) moving
with velocity vector \(\vec{v}\) through electric field with strength and
direction defined by \(\vec{B}\). The units of \(\vec{B}\) are \(T\), Tesla.
Interestingly a faster moving charge will have a greater force exerted on it.
The magnitude of this force can be calcualted through
\[F = qvB\sin(\phi)\]
Where \(\phi\) is the angle between \(v\) and \(B\). This force will always be
perpendicular to the plane defined by the velocity and magnetic field
directions. This can be simulated with the right hand rule; if one curls their
fingers from \(v\) to \(B\) and extends the thumb, it will be in the direction
of the force. \par
The Lorentz Force Law tells us how to combine the effects of magnet and
electric fields on a moving charge. Intuitively enough, it essentially just
says "add them you Drongo"
\[\vec{F} = q\vec{E} + q\vec{v}\times\vec{B}\]
Because a charge in a field will tend to move in an arc, it is clear that if
the area the charge is in is large enough, it will eventually trace out a
circle. If we want to find the radius of that circle, perhaps for desigining
a Cyclotron or similar, we can use the equation
\[r = \frac{mv}{qB}\]
This assumes a charge of mass \(m\) with velocity \(v\) moving in a field
at right angles to its velocity plane. The period of this rotation is given
by
\[T = \frac{1}{f} = \frac{2\pi m}{qB}\]
Interestingly enough, independent of \(v\).

\subsubsection*{Lorentz Force}

When working with both an electric field and a magnetic field, it is often
useful to have the two perpendicular, such as in the case of a cathode ray
tube. \par
Another application of these perpendicular fields is an ion velocity filter,
where one uses the fact that magnetic force is proportional to velocity to
filter out charged particles of other velocities. This is done by balancing the
electrical and magnetic fields such that ions of the desired velocity will have
balanced forces from the two, while other velocities will have larger or
smaller forces, causing them to crash into the side of the chamber. To balance
in this way, one simply needs to solve the equality
\[qE = qvB \Rightarrow v = \frac{E}{B}\]
This same process can be used to construct a simple mass spectrometer, a device
which measures the charge to mass ratio of ions. By accelerating charges in an
electric field, they will end up with
\[v \propto \sqrt{\frac{q}{m}}\]
And can then be passed through an ion filter to measure velocity.

\subsubsection*{The Hall Effect}

If a magnetic field is running through a wire with a current, the deflection
caused by the magnetic field will result in a build up of negative charges on
one side, creating a potential difference between the two sides of the wire.
This is known as the Hall Effect. The magnitude of this effect continues to
increase until the force exerted by the created electric field is equivalent to
the external magnetic field within the wire, i.e.
\[F_E = F_B\]
is the condition for the process to end. This can be used to measure the drift
velocity within the material because the force due to the magnetic field is
proportional to the velocity of the electrons. The final voltage across the
wire is known as the Hall Voltage for the material.

\subsubsection*{Origin of a Magnetic Field}

Magnetic fields can be created in two ways. The first of these is by magnetic
materials, and the second is by currents. A current produces a magnetic field
according to the Biot-Savart Law, which takes the form
\[\mathrm{d}\vec{B} 
= \frac{\mu_0}{4\pi}\frac{I\mathrm{d}\vec{s}\times\hat{r}}{r^2}\]
Where \(\mathrm{d}\vec{B}\) is the section of magnetic field at a distance
\(r\) in a direction \(\hat{r}\) from the current carrier, \(\mu_0\) is the
vacuum permeability and \(\mathrm{d}\vec{s}\) is the rate of change of the
current carrying surface at the relevant point. \par
\(\mu_0\), the vacuum permeability is rather like the vacuum permittivity we
use for electric fields. Like permittivity, we can replace \(\mu_0\) with a
determined \(\mu\) for a non-vacuum material. \par
This law gives us the right hand rule for a wire. If one places their thumb
along the direction of current in a wire, and wraps their fingers around, the
fingers will indicate the direction of magnetic field. \par
Much as we try to use Gauss' Law rather than Coulomb's law in electrostatics,
the complexity of the Biot-Savart law means it is often better to use Ampere's
law when dealing with magnetic fields.

\subsubsection*{Ampere's Law}

Ampere's law states that
\[\oint B\cdot\mathrm{d}s = \mu_0I\]
i.e. for a closed loop around a current carrying path \(s\), the sum of the
magnetic field \(B\) dotted with the rate of change of the path \(\mathrm{d}s\)
will be equal to the vacuum permeability multiplied by the enclosed current.
For the magnetic field around a wire, this yields
\[B = \frac{\mu_0I}{2\pi r}\]
For an internal section of radius \(r\) within a larger wire of radius \(R\),
Ampere's law tells us that the magnetic field enclosed will be
\[\abs{B} = \frac{\mu_0Ir}{2\pi R^2}\]
When working with Ampere's law it is important to consider net current; if one
wire carrying \(3\mathrm{A}\) in one direction is enclosed alongside another
carrying \(1\mathrm{A}\) in the opposite direction, the total current is
\(2\mathrm{A}\) in the first direction. \par
For a long solenoid, with \(n\) turns per metre, we can find the internal
magnetic field using Ampere's law.
\[B = \mu_0nI\]
This is independent of the diameter of the solenoid. For a real solenoid, this
only applies near the centre. \par
For an arc of current \(I\) at a radial distance \(r\) traversing an angle
\(\theta\) (in radians), the magnetic field strength at the centre is given by
\[B = \frac{\mu_0I\theta}{4\pi r}\]
Two adjacent current carrying wires will exert a force on each other due to
their induced magnetic fields. The magnitude of this force by one of these
wires \(b\) on the other \(a\) is given by
\[F_{ba} = \frac{\mu_0I_aI_bL_b}{2\pi d}\]
Where \(d\) is the distance between the two. If the two currents are in the
same direction they will attract each other, while if they are opposite they
will repel. This is the result of the more general equations
\[\vec{F} = q\vec{v}\times\vec{B}\]
\[\vec{F} = i\vec{L}\times\vec{B}\]
For the magnetic force on a moving charge and the magnetic force on a current
respectively.

\subsubsection*{Faraday's Law}

Faraday's Law of induction is one of Maxwell's equations. The law states that
a change in magnetic flux causes a potential difference. In practice, this
means that moving a magnet towards or away from a loop of wire causes a current
and voltage to appear in the loop. The direct of this current is such that the
magnetic field induced by it opposes the change in flux. \par
Magnetic flux through an area is defined as
\[\Phi_B = \int_\mathrm{surface} \vec{B}\cdot\mathrm{d}\vec{A}\]
The magnetic flux is the product of the normal area with magnetic field. In
the case that \(B\) and \(A\) are parallel, this is simply
\[\Phi_B = BA\]

\bigskip
Faraday's law can be intuited by considering a metal bar being moved at some
velocity \(v\) through a constant magnetic field of strength \(B\). The effect
of this magnetic field will be to induce a Hall effect within the bar, creating
a potential difference between its two ends. If one then adds a circuit
connecting the ends of the bar, it acts like a battery, dissipating its voltage
across the wire. Thus a current is created. This current induces a magnetic
field, which opposes the direction of motion. This system can be described
by
\[IR = LBv\]
Where \(I\) is the current created by the Hall effect, \(R\) is the resistance
of the external circuit and \(L\) is the length of the metal bar. Thus we see
the power induced is dependent on the velocity. The induced EMF is given by
\[V = -IR = -LBv\]
More generally this can be expressed as
\[V = -\frac{\mathrm{d}BA}{\mathrm{d}t}\]
Where \(A = L\mathrm{d}x\). Thus the potential difference induced by this
system will be \(V\). It turns out we have a definition for \(BA\).
\[\epsilon = -\frac{\mathrm{d}\Phi_B}{\mathrm{d}t}\]
\(\epsilon\) is conventionally used rather than \(V\) for this induced EMF.

\subsubsection*{Lenz's Law}

A solid object in a changing magnetic field will have eddy currents within it.
\par
The negative sign in the expression of Faraday's law is Lenz's Law. It tells us
that the field induced by the current opposes the change in flux. This is
important; if the opposite were true moving a magnet through a loop would cause
it to be sucked through. \par
This is an important principles for an application like an AC generator,
jumping rings where a conducting solenoid is used to induce an opposing current
in a metal ring, which appears to jump away from the solenoid or a transformer,
where the magnetic field induced by the current around one side of the
transformer induces a current on the other side with voltage determined by
\[V_S = V_P\frac{N_S}{N_P}\]
Where \(V_S\) is the output or secondary voltage, \(V_P\) is the input or
primary voltage, \(N_S\) is the number of coils on the output side and \(N_P\)
is the number of coils on the input side. Transformers are essential for
changing voltages for power delivery. \par
Lenz's Law is also the reason that a magnet falling through a metal pipe is
slowed as it falls. 

\bigskip
An adaptation of Ampere's law is needed to explain the phenomena of a magnetic
field appearing between charging capacitor plates, in addition to other
phenomena. This is necessary because the simple version of the law fails to
describe magnetic fields induced by changing ``electric flux'' or \textit{
displacement current}. This adaptation yields
\[\oint \vec{B}\cdot\mathrm{d}\vec{s} 
= \mu_0I + \mu_0\epsilon_0\frac{\mathrm{d}\Phi_E}{\mathrm{d}t}\]
This is the fourth of Maxwell's equations, known as the Ampere-Maxwell Law.\par
Maxwell's equations are quite beautifully tied together by the equation for the
speed of light. Because a photon is a parallel electric and magnetic field
propagating through space, it is intuitive that it is in some way dependent on
Maxwell's equations, and indeed the speed of light is given by
\[\frac{1}{\sqrt{\epsilon_0\mu_0}}\]

\subsubsection*{Magnetic Materials}

A variety of magnetic materials exist. All of these materials are magnetic
dipoles, such as a current in a loop or a bar magnet. We define the magnetic
dipole moment \(\mu\) as
\[\vec{\mu} = I\vec{A}\]
This is similar to the electric dipole moment \(\vec{p} = a\vec{d}\) discussed
earlier. In a magnetic field, it experiences the torque
\[\vec{\tau} = \vec{\mu}\times\vec{B}\]
\[U = -\vec{\mu}\cdot\vec{B}\]
Protons, neutrons and electrons all have a magnetic dipole moment. The magnetic
properties of matter largely arise from these moments. The magnetic dipole
moment of an electron is much larger than that of a proton, which is a little
under three times that of a neutron. Thus, the overall moment of an atom is
largely determined by its electrons. We can conceptualise this as electrons
moving around a nucleus, i.e. a current, creating a magnetic field. Therefore
all matter is magnetic; though not necessarily very strongly. In many atoms
however, the moments sum to zero. Even if a single atom doesn't, it may cancel
with adjacent atoms. \par
Materials in which these particles do not cancel each others fields are more
significantly magnetic. In a \textit{paramagnetic material} the magnetic moment
of an individual atom is non-zero. The individual atoms will try to align, but
will be unable to due to thermal agitation. This will lead to a skew in the
overall alignment, causing a magnetic field. \par
In \textit{diamagnetism} the magnetic moment of each individual atom is zero
unless there is an external field. If there is, a magnetic moment is induced
in the opposite direction to the external field. Thus, the material will be
repelled from the pole of a stron magnetic. This property actually exists for
all atoms, but is generally quite weak. \par
\textit{Ferromagnetism} is the most common form, seen in bar magnets and
similar objects. In these materials, adjacent atoms ``collaborate'' via
exchange coupling, causing the atoms to align and creating a strong magnetic
field. There are few of these materials, with the most well known one being
iron. Ferromagnetic materials are used in settings like MRI machines. This
doesn't happen inherently; different regions within a lump of iron may be
differently aligned. However, when a strong field is applied to the material,
it can become aligned, creating a strong magnet. If the material is heated,
thermal agitation can ruin this alignment. Ferromagnets can be wrapped in
wire to create strong electromagnets.
\[B_\mathrm{total} = \mu_0nI + B_\mathrm{Fe}\]
Is the equation for the magnetic field created by wrapping an iron magnet of
strenght \(B_\mathrm{Fe}\) in \(n\) turns of wire with current \(I\) through
them. This can be alternately expressed as
\[B_\mathrm{total} = \mu nI\]
Where \(\mu\) is a property of the iron and \(\mu \gg \mu_0\). 

\section*{Fluids}

A fluid is a substance that can flow; generally liquids and gases. They will
conform to the boundaries of any container in which they are placed. Formally,
they are defined as materials which cannot support shearing stresses.

\subsubsection*{Elasticity}

The capacity of a material to stretch is described by its \textit{Young's
modulus}, \(Y\)
\[\frac{F}{A} = Y\frac{\Delta L}{L}\]
Where \(F\) is the force exerted across an area \(A\), \(\Delta L\) is the
change in length of the object of initial length \(L\). The atoms in the
material behave similarly to ideal springs when below the deformation limit of
the material. \par
Fluids are not elastic; when a shear is applied to a fluid, it flows aside.

\bigskip
Density of a fluid describes the mass of a unit per unit volume.
\[\rho = \frac{\Delta m}{\Delta V} 
\left(=\frac{\mathrm{d}m}{\mathrm{d}V}\right)\]
Where \(m\) is the mass contained in the volume \(V\). For a body of uniform
material
\[\rho = \frac{m}{V}\]
\(\rho\) is measured in \(\mathrm{kgm}^{-3}\). The density of gasses varies
significantly whereas liquids do not, because gases are dramatically more
compressible.

\bigskip
Pressure exerted by a fluid on an object immersed in that fluid is given by
\[p = \frac{F}{A}\]
Where \(F\) is the force exerted and \(A\) is the surface area of the object.
Pressure is measured in \(\mathrm{Nm}^{-2}\), also known as \(\mathrm{Pa}\),
Pascals. Pressure occurs due to the net force of molecules of gas colliding
with the walls of a body. For a liquid, it occurs due to gravity pulling the
liquid against the walls.
\[p = p_0 + \rho dg\]
The above equation describes the pressure within a liquid with surface pressure
\(p_0\), density \(\rho\) at a depth \(d\) under gravity \(g\). This formula
holds for any incompressible fluid. It is worth noting that is not dependent on
area in any way; due to the pressure from the walls, a higher or lower area
does not effect the pressure. \par
\[\Delta p = \rho gh\]
Because of this, pressure is directly related to depth \(h\) by the above
equation. \par
The density of air above the earth is higher near the surface, due to gravity.
Most of the variation in air pressure is due to whether events. \par
Gauge pressure is the pressure measured by a tyre gauge, i.e. measured with
respect to atmospheric pressure. Thus
\[p_\mathrm{gauge} = p - 1\mathrm{Atm}\]

\subsubsection*{Hydraulics}

A hydraulic mechanism like a car jack works because, given a system where one
can pressurise water from one point to increase pressure below another point,
we can modify the ratio of the areas of the two ends of the system to create a
mechanical advantage.
\[p_1 = \frac{F_1}{A_1} = p_2 = \frac{F_2}{A_2} + \rho gh\]
\[\Rightarrow F_2 = \frac{A_2}{A_1}F_1 - \rho gh A_2\]
The above equation relate the force exerted by the person operating a hydraulic
jack, \(F_1\) on an area \(A_1\) to the force exerted on the other end \(F_1\)
across area \(A_2\). Thus, for a small \(h\), the mechanical advantage is given
by
\[F_2 \approx \frac{A_2}{A_1}F_1\]
The force exerted by the jack on the vehicle it lifts is increased by factor
\(\frac{A_2}{A_1}\) as compared to the force \(F_1\) input by the user.

\subsubsection*{Barometer}

A barometer is a device for measuring pressure. It works by using an inverted
tube filled with water, and upending this tube into a basin which is partially
filled with water. Due to gravity the water in the tube will press down into
the basin, causing a rise the the water level, creating a vacuum at the top of
the tube. The height of the water above the basin level, i.e. from the basin
level to the beginning of the vacuum, will be dependent on atmospheric
pressure.
\[p_\mathrm{atm} = \rho gh\]

\subsubsection*{Pascal's Principle}

Pascal's Principle states that a change in pressure applied to an enclosed
incompressible fluid is transmitted undiminished to every portion of the fluid,
and to the walls of the containing vessel.

\subsubsection*{Buoyancy and Archimede's Principle}

Archimede's Principle states that a body wholly or partially immersed in a
fluid will be buoyed upward by a force equal to the weight of the fluid
displaced by the body. Thus for a body of mass \(m\)
\[F_b = mg = \rho Vg\]
\[F_b = \rho_\mathrm{fluid}V_\mathrm{submerged}g\]
Essentially a body can float as long as it has a lower density (or effective
density) than the liquid it is immersed in. For example, given a floating cube
of ice, it has a buoyancy force given by
\[F_b = \rho_\mathrm{water}L^3g\]
When fully submerged, assuming a sidelength \(L\), we can then find the
carrying capacity of this cube through
\[\rho_\mathrm{ice}L^3g + C = F_b\]
Where \(C\) is the carrying capacity.

\subsection*{Fluid Dynamics}

When considering dynamic fluids rather than static fluids, one needs to
consider conservation of energies. An ideal fluid is one in which the velocity
if the fluid is constant at all points in time. An incompressible liquid is one
with a constant density which cannot be changed. A nonviscous flow is a flowing
fluid which doesn't resist the flow. Honey is an example of a viscous liquid.
\par
The equations examined are targeted at liquids which have all three of these
properties. Thus they work well for water, reasonable well for air under some
conditions and poorly for many other fluids. \par
A streamline is a path traced out by a fluid element. The velocity of a fluid
at a point is at a tangent to the streamline and streamlines may not cross in
ideal cases. \par
There are two crucial equations for fluid dynamics.
\[A_1v_1 = A_2v_2\]
This is the \textit{continuity equation}; this tells us that the area at a
point multiplied by the liquids velocity is a constant, i.e. the volume flow
rate is a constant. It is for this reason that the stream from a tap narrows as
it falls, due to acceleration from gravity. \par
This is extended by Bernoulli's Equation, which gives us a conservation of
energy for liquids.
\[p + \frac{1}{2}\rho v^2 + \rho gy = \mathrm{constant}\]
Where \(p\) is the pressure of the liquid, \(\rho\) is its density, \(g\) is
gravity and \(y\) is the height of the liquid. This tells us that the kinetic
energy per unit volume plus the work per unit volume plus the potential energy
per unit volume is a constant. If \(y\) is small we can state that
\[p + \frac{1}{2}\rho v^2 = \mathrm{constant}\]
An example application of this is to consider the speed at which water will
emerge from a hole \(h\) units down from the surface of a tank of water. If we
take depth \(h\) to be at \(y = 0\), and apply our knowledge that the water is
stationary at the surface we can find
\[p_0 + \frac{1}{2}\rho0^2 + \rho gh = p_0 + \frac{1}{2}\rho v^2 + 0\]
\[v = \sqrt{2gh}\]
Curiously this is the same as for water free-falling a vertical distance \(h\).

\section*{Thermal Physics}

\subsection*{Thermal Properties of Matter}

There are three phases of matter; solid, liquid and gas. The major difference
between these states is in the bonds between the atoms in the matter. They are
never totally stationary, but they are relatively fixed in solids, somewhat
more free in liquids and utterly independent in gases. \par
A state variable tells us about the state of a system (such as pressure,
volume, etc). One of these is that we talk about the number density of atoms
\[\eta = \frac{N}{V}\]
\(\eta\) is the number of atoms (or molecules or particles) per unit volume.
\par
The atomic mass number \(A\) is given by the number of protons added to the
number of neutrons. The atomic mass unit \(\mathrm{u}\) is given by
\[1\mathrm{u} = \frac{m\left(^{12}C\right)}{12}
= 1.66\times10^{-27}\mathrm{kg}\]
and is sometimes known as the Dalton. This is one twelfth of the mass of a
carbon-12 atom. \par
Avogadro's number \(N_A\) is
\[N_A = 6.02\times10^23\]
And this referes to the number of ``elementary units'' per mole. These units
could be atoms, molecules, etc. Thus one mole of carbon twelve is \(N_A\)
carbon atoms. The molar mass of a substance is the mass in grams of one mole of
a substance. \par
Temperature is measured in Kelvin (\(\mathrm{K}\)), which is measured in units
of the same size as Celsius, starting from \(-273.15\degree\mathrm{C}\),
absolute \(0\). \par

\subsubsection*{Phases of Matter}

We can think about the bonds between atoms as a kind of spring system. When
atoms are pushed close together, a strong repulsive force repels them, while
when they are further apart a weaker attractive force draws them together.
If one increases the energy of the system, perhaps in the form of an increase
in temperature, it becomes easier for atoms to break these bonds and change
phase. \par
Within a gas, the temperature tells us something about the behaviour of the
particles. At \(0\mathrm{K}\), the particles are stationary. \par
When heating a liquid, the temperature will be unchanged as the phase change
occurs. Temperature and pressure have a relationship for matter; higher
pressures imply more solid matter, while higher temperature implies less solid
matter. We can therefore find a point, the ``triple point'' on a plot of
temperature against pressure where the matter could change to any phase. \par
Another consequence of this relationship is sublimation; when at very low
pressure, matter will simply turn into a gas. \par
The critical point occurs are high pressure and high temperature, and at this
point a material can be both liquid and gaseous. For most materials, the shape
of the pressure versus temperature plot is similar, with the left hand side at
low temperature solid, the bottom part a wedge of gas and liquid a wedge driven
between the two at relatively high temperature and pressure.

\subsubsection*{Ideal Gas Equation}

An ideal gas obeys the \textit{Ideal Gas Equation}
\[pV = Nk_BT\]
Where \(p\) is pressure, \(V\) is volume, \(N\) is the number of particles,
\(T\) is temperature and \(k_B\) is \textit{Boltzmann's constant}. Most
``ideal'' gases in the real world approximate this equation. This relationship
between \(p\) and \(T\) when all other variables are held constant allows for
the development of some very accurate thermometers. \par
Boltzmann's constant is given by
\[k_B = 1.38\times10^{-23}\mathrm{J\;K}^{-1}\]
Using the \textit{universal gas constant}
\(R = 8.31 \mathrm{J\;K^{-1}mol^{-1}}\) we can rewrite this as
\[pV = nRT\]
Where \(n\) is the number of moles of the gas.

\subsubsection*{Example}
What is the volume occupied by \(1\mathrm{mol}\) of helium attoms at a
temperature of \(20\degree\mathrm{C}\) at a pressure of \(1\mathrm{atm}\)?
\[pV = nRT \Rightarrow V = \frac{nRT}{p} 
= \frac{1\times8.31\times(273 + 20)}{1.013\times10^5} = 0.024\mathrm{m}^3\]

\bigskip
Using this equation, we can find a variety of equilibria for a gas at different
intersections of variables. For instance we can find that
\[\frac{p}{T} = \frac{nR}{V}\]
Implying that if the right hand side is a constant, a change in pressure must
effect a change in temperature. We know about these through
\textit{quasi-static processes}, where we consider the effect of a tiny change
in one variable. Three main types are talked about

\begin{itemize}
    \item The example given above, with constant volume is an
        \textit{isochoric process}
    \item A constant temperature implies an \textit{isothermal process}
    \item A constant pressure implies an \textit{isobaric process}
\end{itemize}

\subsection*{First Law of Thermodynamics}

The work-kinetic energy theorem states
\[\Delta K = W_c + W_\mathrm{diss} + W_\mathrm{ext}\]
i.e. the change in kinetic energy is the sum of work done by conservative
forces (i.e. \(-\Delta U\)) plus the work done by dissipative forces, such as
friction plus the work done by external forces. \par
We define mechanical energy as the \textit{macroscopic} energy of the system.
\[E_\mathrm{mech} = K + U\]
We define thermal energy as the \textit{microscopic} energy of the system.
\[E_\mathrm{th} = K_\mu + U_\mu\]
The total energy of the system is then the sum of the mechanical and thermal
energy of the system. There are multiple forms of microscopic energy; thermal
energy, chemical energy, which is the energy stored in bonds between molecules
and nuclear energy, the energy stored in an atomic nucleus. \par
The internal or microscopic energy is then given by
\[E_\mathrm{int} = E_\mathrm{th} + E_\mathrm{chem} + E_\mathrm{nuc} + \ldots\]
While the overall system energy is giveny by
\[E_\mathrm{sys} = E_\mathrm{mech} + E_\mathrm{int}\]
We often simplify and assume \(E_\mathrm{int} = E_\mathrm{th}\). We can
consider an increase in energy of a system through
\[\Delta E_\mathrm{sys} = \Delta E_\mathrm{mech} + \Delta E_\mathrm{th}
= W + Q\]
Where \(W\) is external work on the system and \(Q\) is external heat transfer
to the system. An example of this can be seen in a diesel engine, where air is
compressed on an upward stroke to a high pressure, at which stage fuel is
injected, immediately igniting due to the high temperature, expanding downward
and pushing the piston, doing work on the engine. \par
When the gas expands in this way, the work done is given by the area under the
\(pV\) curve, from \(V_\mathrm{initial}\) to \(V_\mathrm{final}\). For a closed
loop on a \(pV\) diagram, the total work done is the area inside the loop.
\[W = -\int_{V_i}^{V_f} p\mathrm{d}V\]
For an expanding gas, one where \(V_f > V_i\), negative work is done on the
gas. This is an isothermal process. This integral comes out to be
\[-nRT\log\left(\frac{V_f}{V_i}\right)\]
In an isochoric process,
\(\mathrm{d}V = 0 \Rightarrow W = 0\). For an isobaric (constant pressure)
proces, the work is simply given by \(-p\Delta V\). Finally, we come to the
First Law of Thermodynamics, that
\[\Delta E_\mathrm{th} = W + G\]
In an isothermal process,
\[\Delta T = 0 \Rightarrow \Delta E_\mathrm{th} = 0 \Rightarrow Q = -W\]
In an isochoric process
\[\Delta V = 0 \Rightarrow W = 0 \Rightarrow \Delta E_\mathrm{th} = Q 
= nc_V\Delta T\]
An adiabatic process is one in which \(Q = 0 \Rightarrow \Delta 
E_\mathrm{th} = W\) thus there is no transfer of heat, and energy is
transferred exclusively as work. This is a desireable property in engines and
similar mechanisms.

\subsection*{Joining Macroscopic and Microscopic}

For particles in a gas, we find that the root mean squared speed will be given
by
\[v_\mathrm{rms} = \sqrt{\bar{v^2}} = \sqrt{\frac{3k_BT}{m}}\]
This gives us the equation for the kinetic energy of a molecule in a gas is
given by
\[\bar{K}_\mathrm{molecule} = \frac{1}{2}m\bar{v^2} = \frac{3}{2}k_BT\]
i.e. the average kinetic energy is dependent only on the temperature. This
implies that thermal energy is evenly distributed among particles of a gas. We
can use this to find thermal energy.
\[E_\mathrm{th} = N\bar{K}_\mathrm{molecule} = \frac{3}{2}Nk_BT 
= \frac{3}{2}nRT\]
Thus, the thermal energy of a system is dependent only on the temperature and
quantity of particles in the system. We can also find that
\[\Delta E_\mathrm{th} = \frac{3}{2}nR\Delta T\]
\[\Delta E_\mathrm{th} = nc_V\delta T \Rightarrow c_V = \frac{3}{2}R\]
Where \(c_V\) is the heat capacity of the gas. \par
We can consider the \textit{mean free path} of a molecule in a gas as the
distance the particle can travel without colliding with another particle or a
side of the container. This yields an equation of
\[\lambda = \frac{1}{4\sqrt{2}\pi r^2\eta}\]
Where \(\lambda\) is this mean free path length, and \(\eta\) is the previously
discussed number density.

\subsubsection*{Example}
We can calculate the mean free path for nitrogen-2 at \(300\mathrm{K}\) at
pressure \(1\mathrm{atm}\), assuming a radius of
\(r = 1\times10^{-10}\mathrm{m}\) as follows. First, we find the number density
\(\eta\) of the particles through
\[pV = Kk_BT \Rightarrow \eta = \frac{N}{V} = \frac{p}{k_BT}
= \frac{1.013\times10^5}{1.38\times10^{-23}\times300}
= 2.44\times10^{25}\mathrm{m}^{-3}\]
We can then use this to find \(\lambda\) through the previous equation.
\[\lambda = \frac{1}{4\sqrt{2}\pi(1\times10^{-10})^2\times2.44\times10^{25}}
= 2.3\times10^{-7}\mathrm{m}\]

\section*{Modern Physics}

To fill in the gaps between Coulombs laws, Newton's Law of gravity and other
foundational parts of physics, modern physicists in the twentieth century
extended our understanding by adding Newton's laws of special and general
relativity, in addition to the strong and weak nuclear forces. This was the
foundation of the standard model, which with the discovery of the Higgs boson
led to us feeling we had a better grasp on the universe. \par
Of course dark matter and dark energy and the discovery thereof somewhat
damaged that. Experiments made various discoveries about the nature of
electromagnetism, such as the relation of the energy of an electron the the
potential it was accelerated across, given by
\[\frac{1}{2}mv^2 = eV\]
A unit commonly used in this section is the electron volt, given as
\(1.6\times10^{-19}\mathrm{J}\). An electron accelerating across a
\(1\mathrm{V}\) potential difference gains \(1\mathrm{eV}\) of kinetic
energy. \par
We could find the energy of an electron orbiting a proton at a velocity of
\(2.19\times10^6\mathrm{m\;s^{-1}}\) with radius
\(5.29\times10^{-11}\mathrm{m}\) by understanding that the two energies
involved are the kinetic energy of the electron and the electric potential
between the electron and the proton.
\[E = K + U = \frac{1}{2}mv^2 + \frac{1}{4\pi\epsilon_0}\frac{-e^2}{r}
= -2.17\times10^{-18}\mathrm{J}\]
Another important quantity for this unit if Planck's constant \(h\),
defined by
\[h = 6.63\times10^{-34}\mathrm{Js}\]


\subsubsection*{Photoelectric Effect}

When shining light on a metal with electrons, one can knock electrons loose
from the metal. When doing this, one needs to fire photons with high enough
energy to break the binding energy of the electron. Thus when examining this
effect the kinetic energy of electrons knocked free in this way is given by
\[K = E_\mathrm{photon} - E_0\]
Where the energy of the photon is dependent on its frequency, while the energy
required to free the electron is dependent primarily on the \textit{work
function} of the metal; i.e. the minimum amount of energy required to free an
electron. \par
For instance, we could consider a photon with wavelength \(525\mathrm{nm}\)
colliding with metallic cesium with a work function of \(3.43\times10^{-19}J\)
and find the velocity of the resultant photoelectron.
\[E_\mathrm{photon} = hv = \frac{hc}{\lambda} 
= \frac{6.6\times10^{-34}\times3\times10^8}{525\times10^{-9}}
= 3.78\times10^{-19}\]
\[K = 3.78\times10^{-19} - 3.43\times10^{-19} = 3.5\times10^{-20}\mathrm{J}\]
\[\frac{1}{2}{9.11\times10^{-31}}v^2 = 2.5\times10^{-20} \Rightarrow
v = 2.8\times10^5\mathrm{m\;s^{-1}}\]
A photon with an energy of \(625\mathrm{nm}\) would lack the energy to knock
loose an electron, and so we would not observe the photoelectric effect in that
case. \par
Einstein submitted three postulates on the behaviours of this effect, those
being

\begin{itemize}
    \item The light of a given frequency \(f\) consists of discrete
        \textit{quanta}, individual particles, each having energy of
        \(E = hf\), travelling at the speed of light.
    \item These quanta are emitted or absorbed in discrete packets; while
        a metal might absorb \(1\) or \(2\) quanta, it cannot absorb \(1.5\).
    \item A light quantum absorbed by a metal transfers all of its energy to a
        single electron.
\end{itemize}

Light can be understood as a wave with momentum given by
\[p = \frac{E}{c}\]
This can also be expressed in quantum theory as
\[E = hf = \frac{hc}{\lambda} \mcom p = \frac{E}{c} = \frac{h}{\lambda}\]
Special relativity also states that
\[E = \sqrt{(pc)^2 + (mc^2)^2}\]

\bigskip
When we observe these collisions, we often use the Compton effect to understand
how the photon and electron scatter apart. The equations for this are
\[\lambda_f - \lambda_i = \frac{h}{mc}(1 - \cos(\theta))\]
Here, \(\frac{h}{mc}\) is the \textit{compton wavelength} of the particle.
\(\theta\) is the angle of the photo relative to the original direction of
travel.

\bigskip
The wave nature of light observed by Young's double slit experiment was also
observed in similar experiments performed with electrons. In addition, when
measures were taken to reduce the rate of photons to such a low level that only
single photons passed the slit at a time, the same patterns were once more
confirmed. Thus, it is clear that photons display both wave and particle
behaviour.

\begin{itemize}
    \item Waves are essential for explaining refraction, diffraction and
        interference; macroscopic effects which we observe in the real world.
    \item The particle nature of light is necessary to explain the
        photoelectric and Compton effects, in addition to other microscopic 
        phenomena.
\end{itemize}

\subsection*{Wave Particle Duality}

\subsubsection*{Bragg's Law}

When light like an x-ray collides with a crystalline structure such as a slab
of common salt, the scattered rays can constructively interfere according to 
\[2d\sin(\theta) = m\lambda\]
For \(m \in \N\), where \(d\) is the distance between layers of the crystal,
\(\theta\) is the angle of incidence and \(\lambda\) is the wavelength of the
light. \par
As an example we can consider a beam of x-rays with wavelength
\(30\mathrm{pm}\) hitting a crystalline lattic with spacing \(0.3\mathrm{nm}\).
What is the minimum angle resulting in constructive interference?
\[2d\sin(\theta) = m\lambda\]
\[m = 1 \Rightarrow \sin(\theta) = \frac{\lambda}{2d}
= \frac{3\times10^{-11}\mathrm{m}}{2\times3\times10^{-10}\mathrm{m}} = 0.05\]
\[\theta = \arcsin(0.05) \approx 0.05 \approx 2.87\degree\]
If we have a powder or similar collection of crystals in random orientation,
we can use Bragg's law to identify the material. If, rather than carefully
controlling \(\theta\) we allow it to be more or less random, for the majority
of crystals no constructive interference will occur, however for those that do
the interference will tend to produce circular light patterns on a screen they
are projected onto. The spacing of these fringes is dependent on the material,
yielding different radii for \(m = 1, 2, 3, \ldots\).

\subsubsection*{De Broglie Wavelength}

De Broglie gave us that for a photon
\[E = pc = hf \Rightarrow p = \frac{h}{\lambda}\]
This also suggested a relationship between wavelength and momentum, the De
Broglie wavelength given by
\[\lambda = \frac{h}{p} = \frac{h}{mv}\]
If calculated for objects of real world size, this quantity is so miniscule as
to be undetectable, while for tiny particles like electrons, it can have a
significant effect. \par
In experiments, physicists Davisson and Thompson used electron beams projected
at a crystal to measure using Bragg's law the wavelength of the electrons,
finding that their wavelength was as predicted by the De Broglie wavelength.

\subsubsection*{Spectra}

When one passes a light through a gass and records the wavelengths that are
emitted through the other side, they will find that while most light passes
through without interaction, certain wave lengths will be missing. Likewise
when a gas is excited, it will release photons at a small number of very
specific wavelengths. To predict these emission spectra for hydrogen we can
use the Rydberg formula
\[\frac{1}{\lambda} = R\left(\frac{1}{m^2} - \frac{1}{n^2}\right)\]
Where \(R\) is the Rydberg constant \(1.097\times10^7\mathrm{m}^{-1}\), \(m\)
is the series; \(1\) for the ultraviolet series, \(2\) for the visible series
and \(3\) for the infrared series and \(n\) is the index within that series.
To find the index of a given energy state in a hydrogen atom we can use the
formula
\[\sqrt{\frac{-13.6\mathrm{eV}}{E\mathrm{eV}}} = n\]
Where \(E\) is the energy of the energy state one wants to find the index of.
For example, if we wanted to find which energy state corresponds to a binding
energy of \(-3.4\mathrm{eV}\) we would use
\[n = \sqrt{\frac{-13.6\mathrm{eV}}{-3.4\mathrm{eV}}} = 2\]
The pattern these energy states follow is of initially quite discrete bands
gradually growing tighter and tighter together.
The reason for this pattern must the the only force that an electron really
feels; the electrostatic force between the electron and it's nucleus. Niels
Bohr tried to apply classical mechanics to solve this problem and found that
he was unable to, until he stipulated the assumption that electrons had angular
momentum in quantised units. Using this assumption, he found that electrons
could only orbit at specific radii and thus have certain quantised energy
levels. \par
Thus the reason for the observed emission spectra is the idea of energy levels.
Atoms have different states of excitation and cannot take on other states, so
they will only absorb energy from photons of appropriate energies; i.e.
wavelengths. Likewise they can only emit energy as part of a state transition,
which must be in the form of some discrete quantity. \par
This yields the following equation for the energy states of an atom
\[E_n = -\frac{z^2me^4}{8\epsilon_0^2h^2}\frac{1}{n^2}\]
Where \(z\) is the charge of the nucleus; i.e. it's atomic number, \(m\) is
the mass and \(e\) is the charge of an electron and \(n\) is the energy state.
\par
This quantised situation does not work only for the particle model of an
electron. If we take an electron to be a wave, and consider it's position
within an electric potential energy well, much like a gravitational well,
we can see that at the bottom of the energy well it will be trapped inside
the well, oscillating between the walls. It will need to take on a harmonic
process inside the closed tube to maintain this state. Thus the \(n\) value
of energy states; in some sense they are analogous to the harmonics of a
closed tube. \par
As an example. we can consider an atom with stationary states
\(E_1 = 0\mathrm{eV}\), \(E_2 = 3.0\mathrm{eV}\) and \(E_3 = 5.0\mathrm{eV}\).
We can then ask what wavelengths might be observed in the absorption or
emission spectra. \par
The only transitions upward are \(+3\mathrm{eV}\) and \(+5\mathrm{eV}\) as
absorption must start from the first energy state. We
can find the wavelengths absorbed using the photon energy relations.
\[E = hf \Rightarrow f = \frac{E}{h}\]
\[f = \frac{3}{h} = 7.25\times10^{14}\mathrm{Hz} \Rightarrow \lambda
= 414\mathrm{nm}\]
\[f = \frac{5}{h} = 1.21\times10^{15}\mathrm{Hz} \Rightarrow \lambda
= 248\mathrm{nm}\]

\subsection*{Quantum Numbers}

\subsubsection*{Quantum Angular Momentum}

An electron moving in an orbit either as a wave function or as a particle must
have some angular momentum. This angular momentum is given by the equation
\[AM = \sqrt{\ell(\ell + 1)}\hbar\]
Where \(\ell\) is the angular momentum quantum number, a value in the range
\([0, n)\) where \(n\) is the \textit{principle quantum number} of the given
atom. From \(\ell\) we come to \(m_\ell\) which can take integer values in the
range \([-\ell, \ell]\). This is the magnetic quantum number. \par
Thus for an energy state \(n\) there are \(n\) angular momentum states \(\ell\)
for which there are \(n^2\) magnetic quantum states \(m_\ell\). This yields far
more possible quantised states than simply the energy states of the atom. \par
Continuing the earlier example of a \(-3.40\mathrm{eV}\) energy hydrogen atom
we can find that for \(n = 2\), \(\ell\) can be \(0\) in which case \(m_\ell\)
must be \(0\) or \(\ell\) can be \(1\), in which case we have
\(m \in \set{1, 0, -1}\). Thus there are four possible quantum states that the
atom could be in, each with energy \(-3.40\mathrm{eV}\). \par
When trying to extend this system to multi-electron atoms, physicists initially
considered atoms with electrons all in the lowest energy state. However, while
this worked well for hydrogen and helium, at lithium they found that the
binding energy observed experimentally was much lower than what this model
predicted. This is due to the phenomenon of electron shells; with room for only
two electrons in the first shell, the third must move to a lower level of
binding energy. 

\subsubsection*{Pauli Exclusion Principle}

This is explained by the \textit{Pauli exclusion principle} which elegantly
states that qauntum states must be unique within an atom. Thus for two
electrons we can have \(\ell = 0 = m_\ell\). However this is only a single
unique electron; a problem as helium manages to maintain two in low energy
state. Thus he introduced the concept of spin; all electrons have a spin of
clockwise or anticlockwise. This finally allows for two states in the first
shell
\[\ell = 0, m_\ell = 0, s = \frac{1}{2}\mcom
\ell = 0, m_\ell = 0, s = -\frac{1}{2}\]
Pauli designated spin up as \(\frac{1}{2}\) and spin down as \(-\frac{1}{2}\).
This system explains the electron shells we observe in various atoms, lithium
and higher. The system explains the \(8\) electrons in the second shell, the
\(18\) in the third, etc. \par
Because an electron alone in an outer shell feels a weaker charge than a full
shell, it is easier for atoms to lose these electrons. The energy required to
removed an electron from an atom is dependent on \(z\), the positive charge of
the nucleus. We can use xrays to interrogate atoms to find these charges. When
we fire xray beams at an atom, when these xrays collide with an electron in the
inner shell, they will cause an electron from the next shell up to move down,
causing a photon emission with energy given by the difference in binding energy
between the two shells.

\begin{center}    
    \begin{tabular}{|c|c|c|c|}
        Name & Symbol & Values & Possible \\
        Principal & \(n\) & \(1, 2, 3, ...\) & \(\infty\) \\
        Orbital & \(\ell\) & \([0, n - 1]\) & \(n\) \\
        Magnetic & \(m_\ell\) & \([-\ell, \ell]\) & \(2\ell + 1\) \\
        Spin & \(m_s\) & \(\pm\frac{1}{2}\) & \(2\) \\
    \end{tabular}
\end{center}

The above table summarises the quantum numbers possible in a hydrogen atom.
These four quantum numbers can alse be used to identify the states of
individual electrons in atoms with more than a single electron. \par
The noble gases occur at a maximum number of electrons for a given \(n\).
For \(n = 1\) this is \(2\), \(n = 2 \Rightarrow 8\) etc. Interestingly, if
we look at the spins of these, we will find that they cancel out; the net
angular momentum due to these electrons is \(0\) for noble gases (or any atom
with a full outer shell). \par
For an atom with an atomic number \(z\) we can find the energy of an energy
state \(n\) through
\[E_n = -13.6\frac{z^2}{n^2}\mathrm{eV}\]
Where \(13.6\mathrm{eV}\) is the ground state energy of a hydrogen atom.

\subsubsection*{Characteristic Xrays}

When examining emission spectra from atoms bombarded with photons, a certain
notation is used to discuss the emitted photons and the actions that caused
them. We name the first three shells and transitions between them according to

\begin{figure}[!htb]
    \hspace{0.05\textwidth}
    \begin{minipage}{0.4\textwidth}
        \centering
        \begin{tabular}{c|c|c|c|}
            & \(K\) & \(L\) & \(M\) \\
            \(n = \) & \(1\) & \(2\) & \(3\) \\
        \end{tabular}
    \end{minipage}
    \begin{minipage}{0.4\textwidth}
        \centering
        \begin{tabular}{c|c|c|c|}
            & \(\alpha\) & \(\beta\) & \(\gamma\) \\
            \(\Delta n =\) & \(1\) & \(2\) & \(3\) \\
        \end{tabular}
    \end{minipage}
\end{figure}

Thus, if we knocked an electron out of the \(K\) (\(n = 1\)) shell and the
vacancy was filled by an electron from the \(L\) shell, we would have a
\(K_\alpha\) transition implying a photon emission with energy given by the
difference between the binding energy fo the \(K\) and \(L\) shells. If the
vacancy was instead filled by an electron from the \(M\) shell, we would have
a \(K_\beta\) transition.

\subsubsection*{Electron Shielding}

Because the charge of an electron can ``cancel out'' that of a proton, an
electron in the shell of a nucleus has the effect of reducing the overall
charge of the atom. Thus, rather than being proportional to \(Z^2\) the
characteristic may instead me proportional to \((Z - 1)^2\). We can adapt
our equation to yield
\[\frac{3}{4}13.6(Z - 1)^2\mathrm{eV}\]

\subsubsection*{Heisenberg's Uncertainty Principle}

Heisenbergs uncertainty principle is given by

\[\Delta p\Delta x \geq \frac{\hbar}{2}\]

Where \(\hbar\) is equal to \(h\) divided by \(2\pi\) or
\(1.055\times10^{-34}\mathrm{J\;s}^{-1}\). \par
When observing the distribution of electrons fired through a slit onto a
screen, the arrangement will tend to be a neat bell curve. When introducing
a second slit, a wave interference pattern will again occur. However, if one
monitors the electrons coming through each slit, they will appear to
individually behave in the bell curve one would expect. \par
This is because when the position of the electrons is measured precisely, the
uncertainty in their momentum increases dramatically. It can be considered that
the reason for this is because the act of taking the measurement disrupts the
result. 

\subsubsection*{The Strong Nuclear Force}

The radius of a nucleus is given by
\[R = R_0A^{\frac{1}{3}}\]
Where \(R_0 = 1.2\mathrm{fm}\) and \(A\) is the mass number of the atom. This
implies a constant density for nuclei. This is due to the ludicrous strength of
the strong nuclear force. \par
Where neutrons decay in roughly \(900\mathrm{s}\), protons last \(10^{31}\)
years or more. \par
For a given atom, we term its quantity of protons as \(Z\), neutrons as \(N\)
and nucleons as \(A = Z + N\) (\(A\) is the mass number of the atom). Nuclei
with equivalent \(Z\) but different \(N\) are isotopes of an element.
\[{}_Z^A\mathrm{E}\]
Is the general notation for these values, where \(\mathrm{E}\) is the symbol
for this element.
\[\tensor*[^{238}_{92}]{\mathrm{U}}{}\]
The binding energy of an atom is the total energy required to tear a nucleus
apart into constituent elements. It can be calculated through
\[E = \Delta mc^2\]
This is known as the \textit{nuclear binding energy}. The force this energy is
counteracting is the strong nuclear force. The force is strong enough to
overcome even the huge strength of the electromagnetic force on the scale of
atoms.

\subsubsection*{Radioactive Decay}

The reason that higher elements have more neutrons than protons, is because the
additional neutrons are needed to overcome the repulsion of protons. \par
One method for stabilisation of large unstable nuclei is the emission of alpha
particles (i.e. hydrogen atoms). These emitted hydrogen atoms are high energy
and will ionise (i.e. interact with) other particles. Therefore they have very
weak penetration. The notation for a radioactive decay of this form is
\[\tensor*[^{238}_{92}]{\mathrm{U}}{} \rightarrow
\tensor*[^{234}_{90}]{\mathrm{Th}}{} + \tensor*[^4_2]{\mathrm{He}}{}\]
Another method is through \(\beta\) particle emission, where a neutron decays
to a proton and emits a \(\beta_{-}\) particle (i.e. an electron) to conserve
charge. \(\beta_{+}\) particles (or positrons) can also be emitted.
\[\tensor*[^{32}_{15}]{\mathrm{P}}{} \rightarrow
\tensor*[^{32}_{16}]{\mathrm{S}}{} + e^{-} + \nu\]
\[\tensor*[^{64}_{29}]{\mathrm{Cu}}{} \rightarrow
\tensor*[^{64}_{28}]{\mathrm{Ni}}{} + e^{+} + \nu\]
In a \(\beta\) decay, a neutrino (\(\nu\)) is also emitted. For a \(\beta_-\)
decay, a neutron becomes a proton and electron. For \(\beta_+\), a proton
becomes a neutron an a positron. \par
Finally an excited atom can emit a \(\gamma\)-ray which have very high energy.
\par
Radioactive decay of a substance occurs randomly rather than after a given time
for a given particle. The resultant formula for the remaining quantity of
particles is
\[N(t) = N_0e^{-\lambda t}\]
Where \(N_0\) is the intial quantity of material, \(t\) is the time, and
\(\lambda\) is the decay constant, with value given by
\[\lambda = \frac{\log(2)}{\tau}\]
Where \(\tau\) is one half-life of the material. Another relevant quantity is
the decay rate, \(R\), with value given by
\[R = -\dd{N}{t} = \lambda N_0e^{-\lambda t} \Rightarrow R =R_0e^{-\lambda t}\]
\[\Rightarrow \tau = \frac{\log(2)}{\lambda}\]

\subsubsection*{Carbon Dating}

\(\tensor*[^{14}]{\mathrm{C}}{}\) is produced when cosmic rays collide with
\(\tensor*[^{14}]{\mathrm{N}}{}\) in the upper atmosphere, resulting in the
transition
\[n + \tensor*[^{14}_7]{\mathrm{N}}{} \rightarrow
\tensor*[^{14}_6]{\mathrm{C}}{} + p\]
These \(\tensor*[^{14}]{\mathrm{C}}{}\) atoms then produced carbon dioxide,
just as \(\tensor*[^{12}]{\mathrm{C}}{}\) atoms would and are respirated by
trees and other plant life. Thus, while respirating this plant life will
maintain a roughly constant ratio of \(\tensor*[^{14}]{\mathrm{C}}{}\) to
\(\tensor*[^{12}]{\mathrm{C}}{}\). However, once they die, the
\(\tensor*[^{14}]{\mathrm{C}}{}\) will decay with a half life of around
\(5700\) years. Thus by measuring the ratio of
\(\tensor*[^{14}]{\mathrm{C}}{}\) to \(\tensor*[^{12}]{\mathrm{C}}{}\), one
can date the death of a plant.

\end{flushleft}
\end{document}
